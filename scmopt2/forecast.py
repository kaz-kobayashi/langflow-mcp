"""予測手法と予測システム ABD-Forecast (AutoML Bayes Deep Forecast)"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06forecast.ipynb.

# %% auto 0
__all__ = ['folder', 'forecast_demand', 'forecast_demand_with_features', 'make_excel_forecast', 'forecast_excel',
           'dynamic_inv_excel', 'make_future_dataframe', 'make_forecast_df', 'make_forecast_df_all', 'find_horizon',
           'prepare_index', 'make_learn', 'train_dl', 'predict_using_dl', 'draw_embedding', 'random_forest',
           'show_importance', 'predict_using_rf', 'automl_pycaret', 'automl_all_sub', 'automl_all',
           'predict_using_automl_all_fig', 'predict_using_automl_all', 'predict_using_automl', 'aggregate_demand',
           'compute_safety_stock', 'inventory_comparison', 'Forecast']

# %% ../nbs/06forecast.ipynb 3
import sys
sys.path.append('..')

from .core import *
import scmopt2.abc as abc

import networkx as nx
import numpy as np
import plotly.graph_objs as go
import plotly.express as px
import plotly
import pandas as pd
import random
import string
import datetime
import math
from scipy.stats import norm

from openpyxl import Workbook, load_workbook
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.chart import ScatterChart, Reference, Series
from openpyxl.worksheet.datavalidation import DataValidation
from openpyxl.formatting.rule import ColorScaleRule, CellIsRule, FormulaRule
from openpyxl.styles import Color, PatternFill, Font, Border, Alignment
from openpyxl.styles.borders import Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.comments import Comment

from typing import List, Optional, Union, Tuple, Dict, Set, Any, DefaultDict
from pydantic import BaseModel, Field, ValidationError, validator, confloat, conint, constr, Json, ConfigDict
from pydantic.tools import parse_obj_as
from datetime import datetime, date, time

from statsmodels.tsa.api import SimpleExpSmoothing, Holt, ExponentialSmoothing

# NeuralProphetを入れると streamlitでplotlyが図をはかなくなる！ 
#from neuralprophet import NeuralProphet, set_log_level 
# set_log_level("ERROR")
# 最新版はpipでいれる必要がある（現在0.8) plotly (最新版　5.19) とのバージョン不整合あり
# pytorch-lightningのバージョンは2未満

from fastai import *
from fastai.tabular import *
from fastai.tabular.all import *

from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

#回帰関連の関数のインポート (version 3.3 をpipでインストール； lightgbm は brew でインストールしたあとで）
from pycaret.regression import setup, compare_models, create_model, predict_model, pull, plot_model
from itertools import product

folder = "./data/"

# %% ../nbs/06forecast.ipynb 16
def forecast_demand(demand_df, cust_selected, prod_selected, agg_period="1d", 
                    forecast_periods=1, cumulative=False, lb=0., ub=None, **kwargs):
    """
    NeuralProphetを用いた需要予測（顧客と製品に対して）
    """
    try:
        demand_df.reset_index(inplace=True)
    except ValueError:
        pass
    demand_df["date"] = pd.to_datetime(demand_df["date"])
    demand_df.set_index("date", inplace=True)
    demand_grouped = demand_df.groupby(
        ["cust", "prod"]).resample(agg_period)["demand"].sum()

    dic = {}
    for c in cust_selected:
        for p in prod_selected:
            if (c,p) in demand_grouped and len(demand_grouped[c,p])>=15:
                if cumulative == True:
                    df = pd.DataFrame(demand_grouped[c, p].cumsum()) #累積をとる場合
                else:
                    df = pd.DataFrame(demand_grouped[c, p])
                #try:
                df.reset_index(inplace=True)
                df.rename(columns={"date": "ds", "demand": "y"}, inplace=True)

                model = NeuralProphet(**kwargs)
                metrics = model.fit(df)
                #print(metrics)

                future = model.make_future_dataframe(df, periods=forecast_periods, n_historic_predictions=True)

                forecast = model.predict(future)

                dic[c,p] = (model,forecast)
            else:
                dic[c,p] = None

    return dic, df

# %% ../nbs/06forecast.ipynb 21
def forecast_demand_with_features(demand_df, cust_selected, prod_selected, promo_df=None, 
                                  features=None, agg_period="1d", forecast_periods=1, cumulative=False, lb=0., ub=None, **kwargs):
    """
    Prophetを用いた需要予測（顧客と製品に対して）：特徴ベクトルの追加
    """
    try:
        demand_df.reset_index(inplace=True)
    except ValueError:
        pass

    demand_df["date"] = pd.to_datetime(demand_df["date"])
    demand_df.set_index("date", inplace=True)
    pt = pd.pivot_table(demand_df, values= ["demand"]+features, index= ["date", "prod", "cust"])
    #print(demand_df)
    if promo_df is not None:
        # try:
        #     promo_df.reset_index(inplace=True)
        # except ValueError:
        #     pass
        promo_df["date"] = pd.to_datetime(promo_df["date"])
        promo_df.set_index("date", inplace=True)
        promo_df = promo_df.resample(agg_period).sum()
        promo_df.reset_index(inplace=True)
    
        promo_df.rename(columns={"date": "ds"}, inplace=True)
        promo_df["ds"] = pd.to_datetime(promo_df["ds"]) 
    dic = {}
    for c in cust_selected:
        for p in prod_selected:
            #try:
            if True:
                df = pt.xs(key=(p,c), level=(1,2)).resample(agg_period).sum()
                df.reset_index(inplace=True)
                df.rename(columns={"date": "ds", "demand": "y"}, inplace=True)
    
                model = NeuralProphet(**kwargs)
    
                #特徴の追加
                for f in features:
                    model.add_future_regressor(f)
    
                metrics = model.fit(df)
                #promo_df (regressor_df) と df（訓練用）のdsに重複があるとエラー
                #df, promo_dfのdsに重複がある場合には削除する（日の集約で重なるケースがある）
                promo_df = promo_df[ promo_df["ds"] > df["ds"].iloc[-1] ]
                future = model.make_future_dataframe(df, regressors_df= promo_df, 
                                                     periods=forecast_periods, n_historic_predictions=True)
                
                forecast = model.predict(future)
    
                dic[c,p] = (model,forecast)
            #except:
            #   dic[c,p] = None
    
    return dic, df

# %% ../nbs/06forecast.ipynb 38
def make_excel_forecast(start, finish, period=1, period_unit="日", num_features = 0, holiday=True):
    
    trans = {"時":"h", "日":"d", "週":"w", "月":"M"}
    freq = f"{period}{trans[period_unit]}"

    if freq =="1d" and holiday:
        num_features+=1 #休日を表す列を追加
        jp_holidays = holidays.Japan()
        
    #テンプレ生成
    wb = Workbook()
    ws = wb.active
    wb.remove(ws)
    ws = wb.create_sheet(title="需要")
    ws.append(["日付","需要量"] +[f"特徴{i}" for i in range(num_features)]+["予測", "誤差"])

    time_index = pd.date_range(start, finish, freq= freq)
    
    #時間フォーマット
    for i, idx in enumerate(time_index):
        ws.cell(i+2, 1).number_format = 'yyyy/m/d'
        ws.cell(i+2, 1).value = idx
        if freq =="1d" and holiday:
            if idx in jp_holidays:
                ws.cell(i+2, 3).value = 1
            else:
                ws.cell(i+2, 3).value = 0
    #コメント
    ws.cell(1,1).comment = Comment("日付（自動生成されたもの）", "logopt")
    ws.cell(1,2).comment = Comment("日毎の需要量を入力", "logopt")
    for i in range(num_features):
        ws.cell(1,3+i).comment = Comment("付加的な特徴量を表す数値を入力", "logopt")
    ws.cell(1,3+num_features).comment = Comment("予測値（出力）", "logopt")
    ws.cell(1,4+num_features).comment = Comment("予測誤差（自動計算）", "logopt")
    
    #日付・時刻バリデーション
    dv = DataValidation(type="date") 
    ws.add_data_validation(dv)
    dv.add('A2:A1048576') 
    
    #データチェック
    dv = DataValidation(type="decimal", allow_blank=False)
    ws.add_data_validation(dv)
    dv.add('B2:B1048576') 

    # 特徴量のデータ検証（なし！）
#     dv = DataValidation(type="whole",
#                     operator="greaterThanOrEqual",
#                     formula1=0)
#     ws.add_data_validation(dv)
#     c1 = ws.cell(2,3)
#     c2 = ws.cell(2,2+num_features)
#     dv.add(f'{c1.column_letter}2:{c2.column_letter}1048576') 
    
    #幅
    ws.column_dimensions["A"].width = 15
    return wb

# %% ../nbs/06forecast.ipynb 42
def forecast_excel(wb, valid_start, predict_start):
    ws = wb["需要"]
    data = ws.values
    cols = next(data)[:]
    data = list(data)
    demand_df = pd.DataFrame(data, columns=cols).dropna(how="all") 
    #demand_df = demand_df.dropna(axis=1, how="all") #すべてが欠損値の列を削除
    demand_df.fillna(0., inplace=True)
    forecast_df = demand_df[ demand_df.日付 < pd.to_datetime(predict_start) ]
    #訓練データ生成
    df = forecast_df.drop(["予測","誤差"], axis=1)
    df = df.rename({"日付":"date", "需要量":"demand"}, axis=1).copy()
    #日付から複数の特徴を抽出
    add_datepart(df, "date", drop=True, time=False)
    #訓練
    best, result_df = automl(df, horizon=valid_start, model_name="all" )

    if type(best) != type([]):
        best = [best]
        print(best)
    #予測用データ生成
    df = demand_df.drop(["予測","誤差"], axis=1)
    df = df.rename({"日付":"date", "需要量":"demand"}, axis=1).copy()
    #日付から複数の特徴を抽出
    add_datepart(df, "date", drop=True, time=False)
    #予測
    forecast = predict_model(best[0], df)
    demand_df["予測"] = forecast.Label
    demand_df["誤差"] = demand_df["需要量"]-forecast.Label
    valid_df = demand_df[ (demand_df.日付 < pd.to_datetime(predict_start))& (demand_df.日付 >= pd.to_datetime(valid_start))]

    for row in ws.iter_rows(min_row=1, min_col=1, max_row=1):
        for cell  in row:
            if cell.value=="予測":
                forecast_col = cell.column
                forecast_column_letter = cell.column_letter
                break
        else:
            raise ValueError("「予測」列が見つかりません．追加してください．")
            
    for i,y in enumerate(forecast.Label):
        ws.cell(i+2, forecast_col).value = float(y)
        ws.cell(i+2, forecast_col+1).value = f"=B{i+2}-{forecast_column_letter}{i+2}"     #誤差の計算
    
    return wb, best, result_df, forecast, demand_df, valid_df

# %% ../nbs/06forecast.ipynb 46
def dynamic_inv_excel(wb, valid_start, predict_start, valid_df, demand_df, h, fc, vc=0., z=2.33):
    std = valid_df["誤差"].std()
    d = demand_df[ (demand_df.日付 < pd.to_datetime(predict_start)) ].需要量.mean()
    omega = 1.
    Q = np.sqrt(2*fc*d/(h+0.0001)/omega)
    CT = Q/d #サイクル時間
    S = z*std*np.sqrt(CT) #安全在庫量
    demand = demand_df[ (demand_df.日付 >= pd.to_datetime(valid_start))]
    demand_positive = np.maximum(demand.予測,0)
    cost, order = optinv.ww(list(demand_positive), fc=fc, vc=0., h=h)
    print(cost,order)
    ws = wb.create_sheet("在庫シミュレーション")
    #"在庫費用","変動費用","固定費用" #動的なパラメータの場合には追加
    ws.append(["日付","需要量", "予測", "誤差", "累積誤差", "発注量","補正発注量","在庫量"])

    #時間フォーマット
    for i, row in enumerate(demand.itertuples()):
        ws.cell(i+2, 1).number_format = 'yyyy/m/d'
        ws.cell(i+2, 1).value = row.日付
        ws.cell(i+2, 2).value = row.需要量
        ws.cell(i+2, 3).value = row.予測
        ws.cell(i+2, 4).value = f"=B{i+2}-C{i+2}"     #誤差の計算
        if i==0:
            ws.cell(i+2, 5).value = f"=D{i+2}" #累積誤差  
            ws.cell(i+2, 7).value = f"=F{i+2}" #補正発注量
            ws.cell(i+2, 8).value = f"= {S} +G{i+2}-B{i+2}" #在庫量(Sは初期在庫量)
        else:
            ws.cell(i+2, 5).value = f"=IF(F{i+2}>0, IF(G{i+2}>=0,D{i+2}, G{i+2}+D{i+2}), E{i+1}+D{i+2})" #累積誤差 
            ws.cell(i+2, 7).value = f"=IF(F{i+2}>0, MAX(F{i+2}+E{i+1},0),0)"  #補正発注量
            ws.cell(i+2, 8).value = f"= H{i+1}+G{i+2}-B{i+2}" #在庫量
        ws.cell(i+2, 6).value = order[i] #発注量
    #幅
    ws.column_dimensions["A"].width = 15
    
    #コメント
    ws.cell(1,1).comment = Comment("日付（自動生成）", "logopt")
    ws.cell(1,2).comment = Comment("日毎の需要量", "logopt")
    ws.cell(1,3).comment = Comment("予測値", "logopt")
    ws.cell(1,4).comment = Comment("予測誤差（自動計算）", "logopt")
    ws.cell(1,5).comment = Comment("累積誤差（発注間隔の間に累積された誤差量）", "logopt")
    ws.cell(1,6).comment = Comment("発注量（最適化の結果）", "logopt")
    ws.cell(1,7).comment = Comment("補正発注量（累積誤差を加味した発注量）", "logopt")
    ws.cell(1,8).comment = Comment("在庫量（自動計算）", "logopt")
    return wb

# %% ../nbs/06forecast.ipynb 50
def make_future_dataframe(history_dates, periods, freq='1d'):
    """
    未来の時系列データフレームを生成する関数
    """

    last_date = history_dates.max()
    dates = pd.date_range(
        start=last_date,
        periods=periods + 1,  # An extra in case we include start
        freq=freq)
    dates = dates[dates > last_date]  # Drop start if equals last_date
    dates = dates[:periods]  # Return correct number of periods

    # if include_history:
    #     dates = np.concatenate((np.array(history_dates), dates))
    future = pd.DataFrame({'date': dates})
    #future["date"] = pd.to_datetime(future["date"])
    return future

# %% ../nbs/06forecast.ipynb 55
def make_forecast_df(df, promo_df=None,  agg_period="1d", forecast_periods =1):
    """
     訓練用データフレームと予測用の未来のデータフレームを生成する関数
    """

    future = make_future_dataframe(history_dates=df["date"], periods=forecast_periods, freq=agg_period)
    #未来のデータフレームにも特徴を追加
    #future["date"] = pd.to_datetime(future["date"])
    if promo_df is not None:
        promo_df["date"] = pd.to_datetime(promo_df["date"])
        future = pd.merge(future, promo_df, on="date", how="left")

    #日付から複数の特徴を抽出
    train = df.copy()
    add_datepart(train, "date", drop=True, time=False)
    add_datepart(future, "date", drop=True, time=False)

    return train, future

# %% ../nbs/06forecast.ipynb 59
def make_forecast_df_all(demand_df, promo_df=None,  agg_period="1d", forecast_periods =1):
    """
    全データに対する訓練用データフレームを生成する関数
    """
    if "date" not in demand_df.columns:
        demand_df.reset_index(inplace=True)
    demand_df["date"] = pd.to_datetime(demand_df["date"])
    demand_df.set_index("date", inplace=True)
    future_ = make_future_dataframe(history_dates=demand_df.index, periods=100, freq=agg_period)
    customers = set(demand_df["cust"])
    products = set(demand_df["prod"])
    all_combinations = list(product(future_.date, customers, products))
    df = pd.DataFrame(all_combinations, columns=['date', 'cust', 'prod'])
    future = pd.merge(df, promo_df, on="date", how="left")
    
    train = demand_df.copy().reset_index()
    #日付から複数の特徴を抽出
    add_datepart(train, "date", drop=True, time=False)
    add_datepart(future, "date", drop=True, time=False);

    return train, future

# %% ../nbs/06forecast.ipynb 62
def find_horizon(demand_df, ratio=0.9):
    return pd.to_datetime(demand_df["date"][ int(len(demand_df)*ratio )])

# %% ../nbs/06forecast.ipynb 65
def prepare_index(df, horizon=None):
    if horizon is None:
        valid_length = int(len(df)*0.1)+1
        train_idx = list(range(len(df)-valid_length))
        valid_idx = list(range(len(df)-valid_length, len(df)))
    else:
        date = pd.to_datetime(horizon)
        cond = ((df.Year<date.year))|((df.Year==date.year)&(df.Month<date.month))|((df.Year==date.year)&(df.Month==date.month)&(df.Day<=date.day))
        train_idx = list(np.where(cond)[0])
        valid_idx = list(np.where(~cond)[0])
    return train_idx, valid_idx

# %% ../nbs/06forecast.ipynb 69
def make_learn(df, horizon=None, classification=False):
    """
    深層学習を用いた需要予測用のデータを生成
    """
    #検証用データのインデックスを準備．
    train_idx, valid_idx = prepare_index(df, horizon)

    dep_var = 'demand' #従属変数名

    df_ = df.iloc[:,:]
    df_["Week"] = df_.Week.astype(int)

    cont_names, cat_names = cont_cat_split(df_, max_card = 1000, dep_var=dep_var)

    if classification: #分類問題として取り扱う場合
        #df_["demand"] = df_.demand.astype("int")
        #df_["demand"] = df_.demand.astype("category", ordered=True)
        df_["demand"] = pd.Categorical(df.demand, ordered=True)
    else:
        df_["demand"] = df_.demand.astype("float")
    #df_["Elapsed"] = df_.Elapsed.astype("float")

    # DataLoadersのインスタンスを生成
    to = TabularPandas(df_, procs=[FillMissing, Categorify, Normalize],
                         cat_names = cat_names,
                         cont_names = cont_names,
                         y_names = dep_var,
                         splits = ( train_idx, valid_idx )
    )
    data = to.dataloaders()

    if classification: #分類問題として取り扱う場合
        learn = tabular_learner(data, layers=[200,100], metrics=accuracy)
    else:
        min_ = df_.demand.min()
        max_ = df_.demand.max()
        learn = tabular_learner(data, layers=[200,100], y_range=(min_-0.5,max_+0.5), loss_func=F.mse_loss, metrics=[rmse,mae,msle])

    return learn

# %% ../nbs/06forecast.ipynb 75
# def plot_lr_find(learn):
#     y = np.array(learn.recorder.losses)
#     x = np.array(learn.recorder.lrs)
#     fig = go.Figure()
#     fig.add_trace(go.Scatter(
#             x = x, 
#             y = y,
#             mode='markers+lines',
#             name= "train",
#             marker=dict(
#                 size=10,
#                 color= "blue")
#     ))
#     fig.update_xaxes(type="log")
#     fig.update_layout(title = "Learning Rate Finder",
#                    xaxis_title='Learning Rate',
#                    yaxis_title='Loss')
#     return fig

# %% ../nbs/06forecast.ipynb 78
def train_dl(learn, **kwargs):
    """
    fit_one_cycle法を用いて訓練を行う関数
    """
    learn.fit_one_cycle(**kwargs)

# %% ../nbs/06forecast.ipynb 82
#| echo: false
#| echo: false
# def plot_loss(learn, valid = True):
#     y = np.array(learn.recorder.losses)
#     x = list(range(len(y)))
#     fig = go.Figure()
#     fig.add_trace(go.Scatter(
#             x = x, 
#             y = y,
#             mode='markers+lines',
#             name= "train",
#             marker=dict(
#                 size=10,
#                 color= "blue")
#     ))
    
#     if valid:
#         fig.add_trace(go.Scatter(
#                 x = learn.recorder.iters, 
#                 y = np.array(L(learn.recorder.values[:]).itemgot(1)),
#                 name ="valid",
#                 mode='markers+lines',
#                 marker=dict(
#                     size=10,
#                     color= "orange")
#         ))
#     fig.update_layout(title = "Deep learning performance",
#                    xaxis_title='Iterations',
#                    yaxis_title='Loss')
#     return fig

# %% ../nbs/06forecast.ipynb 86
def predict_using_dl(learn, df, future, classification=False):
    """
    深層学習を用いた予測
    """

    preds0, target0, decoded0, loss0 = learn.get_preds(ds_idx=0, with_decoded=True, with_loss=True)
    preds1, target1, decoded1, loss1 = learn.get_preds(ds_idx=1, with_decoded=True, with_loss=True)

    #テンソルをリストに変換
    if classification:
        prediction = decoded0.T.tolist()+ decoded1.T.tolist()
        target = target0.T[0].tolist()+ target1.T[0].tolist()
    else:
        prediction = decoded0.T[0].tolist()+ decoded1.T[0].tolist()
        target = target0.T[0].tolist()+ target1.T[0].tolist()

#     for t in range(len(df), len(future)):
#         _, future_demand, _ = learn.predict(future.iloc[t])
#         prediction.append( float(future_demand) )

    #予測用のデータローダー作成
    dl = learn.dls.test_dl(future)
    future_predict = learn.get_preds(dl=dl)
    prediction =  future_predict[0].flatten().tolist()
    if classification:
        prediction = future_predict[0].argmax(axis=1)

    # trace1 = go.Scatter(
    #     x = list(range(len(prediction))),
    #     y = prediction,
    #     mode = 'markers + lines',
    #     name = "予測 Forecast"
    # )

    # trace2 = go.Scatter(
    #     x =  list(range(len(target))),
    #     y =  target,
    #     mode = 'markers',
    #     name ="実需要量 Demand"
    # )

    # data = [trace1, trace2]

    # layout = go.Layout(
    #     title  ="深層学習による予測 Forecasting by Deep Learning",
    # )

    # fig = go.Figure(data, layout)
    
    return pd.Series(prediction), float(loss1.mean()), float(1.-((preds1-target1)**2).mean()/((target1-target1.mean())**2).mean())

# %% ../nbs/06forecast.ipynb 93
def draw_embedding(learn, cust=True, pca=True):
    """
    draw embedding
    """

    if cust:
        X = to_np(next(learn.model.embeds[0].parameters()))
    else:
        X = to_np(next(learn.model.embeds[1].parameters()))

    if pca:
        pca = PCA(n_components=2) # 2次元に射影
        Z = pca.fit_transform(X)
    else:
        Z = TSNE(n_components=2, random_state=0, perplexity= min(30, len(X)-1)).fit_transform(X)

    if cust:
        text_ = list(learn.dls.classes["cust"])
    else:
        text_ = list(learn.dls.classes["prod"])
        #ave_demand = pd.pivot_table(all_df, index="cust",values="demand")

    trace = go.Scatter(
        x = Z[:,0],
        y = Z[:,1],
        mode = 'markers+text',
        text= text_,
        marker=dict(
                color='LightSkyBlue',
                size=30,
                opacity=0.5
        )
    )
    data = [trace]
    fig = go.Figure(data)
    return fig

# %% ../nbs/06forecast.ipynb 98
def random_forest(df, horizon=None, feature=None, classification=False):
    """
    ランダム森による需要予測
    """
    #検証用データのインデックスを準備．
    train_idx, valid_idx = prepare_index(df, horizon)
    #選択した特徴ベクトルのみのデータフレームを作る
    if feature is not None:
        df = df[ feature + ["demand"] ]

    y_train = df["demand"].iloc[train_idx]
    X_train = df.drop("demand",axis=1)
    X_train = X_train.iloc[train_idx]
    if classification:
        forest = RandomForestClassifier()
    else:
        forest = RandomForestRegressor()
        #RandomForestRegressor(n_estimators=40, max_samples=600, max_features=0.5,min_samples_leaf=5)
    forest.fit(X_train, y_train)    # 訓練

    importance = permutation_importance(forest, df.drop("demand",axis=1), df.demand, n_repeats=10,
                                 random_state=0)
    return forest, importance

# %% ../nbs/06forecast.ipynb 102
def show_importance(importance, feature, df):
    if feature is None:
        feature = tuple(df.columns[1:])
    imp_df = pd.DataFrame( {"features":feature,"importance":importance['importances_mean']}
                  ).sort_values("importance", ascending=False)
    #fig = px.bar(imp_df,y="features",x="importance",orientation="h")
    return imp_df

# %% ../nbs/06forecast.ipynb 106
def predict_using_rf(df, future, forest, horizon=None, feature=None):
    """
    ランダム木を用いた予測
    """

    #検証用データのインデックスを準備．
    train_idx, valid_idx = prepare_index(df, horizon)

    if feature is not None:
        df = df[ feature +["demand"] ]
        future = future[ feature ]
    #誤差の計算
    X_test = df.drop("demand",axis=1)
    X_test = X_test.iloc[valid_idx,:]
    predict_ = forest.predict(X_test)
    y = np.array(df["demand"][valid_idx])
    error_ = ((predict_ - y )**2).mean()

    #全ての期に対する予測の計算
    try:
        future.drop("yhat", axis=1, inplace=True)
    except:
        pass
    predict_ = forest.predict(future)

    # trace1 = go.Scatter(
    #     x = future.index,
    #     y = predict_,
    #     mode = 'markers + lines',
    #     name = "予測 Forecast"
    # )

    # trace2 = go.Scatter(
    #     x =  df.index,
    #     y =  df["demand"],
    #     mode = 'markers',
    #     name ="実需要量 Demand"
    # )

    # data = [trace1, trace2]

    # layout = go.Layout(
    #     title  ="ランダム森による予測  Forecasting by Random Forest",
    # )

    # fig = go.Figure(data, layout)
    return predict_, error_, 1.- error_/((y-y.mean())**2).mean()

# %% ../nbs/06forecast.ipynb 110
def automl_pycaret(df, horizon=None, num_bests = 5, sort = "R2", model_name=None):
    """
    Prediction using pycaret regression models
    """
    train_idx, valid_idx = prepare_index(df, horizon)
    ratio = len(train_idx)/(len(train_idx)+len(valid_idx))
    df["Week"] = df.Week.astype(int)
    reg = setup(df, target = 'demand', session_id=123, data_split_shuffle=False, preprocess=True, #前処理は必須！
                fold_strategy= 'timeseries', fold=2, train_size=ratio, verbose=False)
    if model_name is None or model_name=="all":
        best = compare_models(n_select=num_bests, include=['dt', 'rf', 'et', 'gbr'], 
                             sort = sort,  cross_validation=False, turbo=False)
    else:
        best = create_model(model_name, cross_validation = False)
    result_df = pull()
    return best, result_df 

# %% ../nbs/06forecast.ipynb 115
def automl_all_sub(demand_df, promo_df, cust_list, prod_list, horizon, agg_period="1d", forecast_periods =1, threshold= 0.05, max_neg_r2 = 10):
    row_list = []
    # max_neg_r2 回 R2 が負になったら，それ以上予測する必要はないので， breakする
    # cust_list と prod_listは需要量の降順になっているものと仮定する． 
    count = 0
    for c,p in zip(cust_list,prod_list):
        df, future = make_forecast_df(demand_df, customer=c, product=p,promo_df= promo_df, agg_period=agg_period, forecast_periods = forecast_periods)
        #try:
        best, result_df = automl(df, horizon, 1)
        result_df.reset_index(inplace=True)
        forecast = predict_model(best, future)
        error = forecast[:len(df)].Label - df.demand
        train_idx, valid_idx = prepare_index(df, horizon)
        fig, hist_dist = optinv.best_histogram(error[valid_idx], nbins = 20)
        r2 = result_df.loc[0,"R2"]
        if r2 < 0.:
            count +=1 
            if count>=max_neg_r2:
                break
        row_dic ={"cust":c, "prod":p, "model":result_df.loc[0,"index"], "rmse": result_df.loc[0,"RMSE"], "r2": r2,
              "forecast": list(forecast[len(df):].Label), "lb":hist_dist.ppf(threshold), "ub": hist_dist.ppf(1.-threshold)}
        row_list.append(row_dic)
        #except ValueError as e:
        #    print(e)
            
    summary = pd.DataFrame(row_list)
    return summary

# %% ../nbs/06forecast.ipynb 117
def automl_all(demand_df, promo_df, horizon, agg_period="1d", forecast_periods =1, threshold= 0.05, max_neg_r2 = 10, abc_threshold=[0.6, 0.2, 0.2]):
    agg_df,category = abc.abc_analysis_all(demand_df, abc_threshold)
    agg_df.reset_index(inplace=True)
    summary = automl_all_sub(demand_df, promo_df, list(agg_df.cust), list(agg_df["prod"]), horizon, agg_period, forecast_periods, threshold, max_neg_r2)
    summary_all = pd.merge(agg_df, summary, how='left')
    return summary_all

# %% ../nbs/06forecast.ipynb 121
def predict_using_automl_all_fig(demand_df, promo_df, summary, customer, product, agg_period='1d', forecast_periods=10):
    dic = summary.set_index(["cust","prod"]).to_dict()
    model_name = dic["model"][customer,product]
    if model_name == model_name: #NaNの判定
        df, future = make_forecast_df(demand_df,  customer, product, promo_df, agg_period, forecast_periods)
        model = create_model(model_name, cross_validation = False)
        return predict_using_automl(df, future, model)
    else: #nanの場合Falseになる
        return -1

# %% ../nbs/06forecast.ipynb 124
def predict_using_automl_all(demand_df, promo_df, summary, customer, product, agg_period='1d', forecast_periods=10):
    dic = summary.set_index(["cust","prod"]).to_dict()
    model_name = dic["model"][customer,product]
    if model_name == model_name: #NaNの判定
        df, future = make_forecast_df(demand_df,  customer, product, promo_df, agg_period, forecast_periods)
        model = create_model(model_name, cross_validation = False)
        result = predict_model(model, future)
        forecast = list(result.Label[len(df):])
    else: #nanの場合Falseになる
        forecast = [ dic["mean"][customer,product] for t in range(forecast_periods) ]
    return forecast

# %% ../nbs/06forecast.ipynb 127
def predict_using_automl(df, future, best, horizon=None):
    """
    AutoMLを用いた予測（回帰）
    """

    #検証データに対する予測
    result = predict_model(best)
    #誤差の計算
    error_ = ((result.Label - result.demand)**2).mean()

    #実需要量のプロット
    trace2 = go.Scatter(
        x =  df.index,
        y =  df.demand,
        mode = 'markers',
        name ="実需要量 Demand"
    )

    #訓練＋未来のデータに対する予測
    result = predict_model(best, future)

    #予測プロット
    trace1 = go.Scatter(
        x = result.index,
        y = result.Label,
        mode = 'markers + lines',
        name = "予測 Forecast"
    )

    data = [trace1, trace2]

    layout = go.Layout(
        title  ="AutoMLによる予測  Forecasting by AutoML",
    )

    fig = go.Figure(data, layout)
    return fig, error_, result

# %% ../nbs/06forecast.ipynb 144
def aggregate_demand(demand_df, flow_df):
    """
    最適化された製品フローデータと需要データから、地点（工場、倉庫）ごとの集約された需要量を計算する関数
    """
    #make digraphs for each product
    G ={}
    Prod = list(set(demand_df["prod"]))
    for p in Prod:
        G[p] = SCMGraph() #nx.DiGraph()
    for row in flow_df.itertuples():
        p = row.prod
        G[p].add_edge(row.from_node, row.to_node, weight= row.flow)
    #pos = G["C"].layout()
    #nx.draw(G["C"], pos=pos,  node_color="Blue", node_size=10)

    ratio = {} # ratio[i,prod, cust] : 各顧客 cust, 製品 prod の需要に対する地点 i の配分率を保存
    for p in Prod:
        for j in G[p].up_order():
            if G[p].out_degree(j)==0:
                # customer
                sum_flow = 0.
                for i in G[p].predecessors(j):
                    sum_flow +=G[p][i][j]["weight"]
                for i in G[p].predecessors(j):
                    ratio[i,p,j] = G[p][i][j]["weight"]/sum_flow
            else:
                # DC
                sum_flow = 0.
                for i in G[p].predecessors(j):
                    sum_flow +=G[p][i][j]["weight"]
                added_ratio = {}
                for i in G[p].predecessors(j):
                    for dc,prod,cust in ratio:
                        if dc==j and prod==p:
                            added_ratio[i,p,cust] = ratio[dc,p,cust] * G[p][i][j]["weight"]/sum_flow
                ratio.update(added_ratio)
    #需要量を表す辞書を準備
    piv_ = pd.pivot_table(demand_df, index=["date", "cust", "prod"], values="demand")
    demand_dic = piv_.to_dict(orient="index")

    #顧客・製品ごとに、配分される地点（工場、倉庫）とratioを保持する辞書を準備
    ratio_for_cp = defaultdict(list)
    for i, prod, cust in ratio:
        ratio_for_cp[cust, prod].append( (i, ratio[i,prod,cust]) )

    #各地点ごとの集約した需要を計算
    agg_demand_dic = defaultdict(int)
    for date_, cust_, prod_ in demand_dic:
        for (i,ratio_) in ratio_for_cp["Cust_"+cust_, prod_]:
            agg_demand_dic[date_, i, prod_] +=  demand_dic[date_, cust_, prod_]["demand"] * ratio_

    #集約した需要を保管したデータフレームを生成
    date_list, node_list, prod_list, demand_list = [],[],[],[]
    for date_, node_, prod_ in agg_demand_dic:
        date_list.append(date_)
        node_list.append(node_)
        prod_list.append(prod_)
        demand_list.append( agg_demand_dic[date_,node_,prod_]   )
    aggregated_demand_df = pd.DataFrame({"date":date_list, "cust":node_list, "prod":prod_list, "demand": demand_list})

    return aggregated_demand_df, G, Prod

# %% ../nbs/06forecast.ipynb 151
def compute_safety_stock(demand_df, agg_demand_df, trans_df, plnt_prod_df, Prod, G):
    """
    倉庫・工場・顧客に対する安全在庫量の計算
    """

    #リード時間データの抽出
    plnt_prod_lt ={}
    for row in plnt_prod_df.itertuples():
        plnt_prod_lt[row.plnt, row.prod] = row.lead_time
    lead_time ={}
    for row in trans_df.itertuples():
        if row.kind == "plnt-dc":
            lead_time["Plnt_"+row.from_node, "DC_"+row.to_node] = row.lead_time
        elif row.kind == "dc-cust":
            lead_time["DC_"+row.from_node,"Cust_"+row.to_node] = row.lead_time
        else:
            print("trans link is incorrect!")
    #需要（顧客ならびに倉庫・工場の集約需要）のグループ化
    agg_period="1d"
    z = 1.65
    try:
        agg_demand_df.reset_index(inplace=True)
    except:
        pass
    agg_demand_df["date"] = pd.to_datetime(agg_demand_df["date"])
    agg_demand_df.set_index("date", inplace=True)
    agg_demand_grouped = agg_demand_df.groupby(
        ["cust", "prod"]).resample(agg_period)["demand"].sum()

    try:
        demand_df.reset_index(inplace=True)
    except:
        pass
    demand_df["date"] = pd.to_datetime(demand_df["date"])
    demand_df.set_index("date", inplace=True)
    demand_grouped = demand_df.groupby(
        ["cust", "prod"]).resample(agg_period)["demand"].sum()

    #安全在庫量の計算
    prod_col, node_col, lt_col, lt_std_col, dem_col, dem_std_col, safety_col = [],[],[],[],[],[],[]
    for p in Prod:
        for j in G[p]:
            #print(p,j
            prod_col.append(p)
            node_col.append(j)
            if j[:5] == "Plnt_" or j[:3] == "DC_":
                mu_ = agg_demand_grouped[j,p].mean()
                sigma_ = agg_demand_grouped[j,p].std()
            elif j[:5] == "Cust_":
                mu_ = demand_grouped[j[5:], p].mean()    # remove "Cust_"
                sigma_ = demand_grouped[j[5:], p].std()
            else:
                print( "no such a node ", j)

            if G[p].in_degree(j)>=1: # not a plant
                sum_flow = sum( G[p][i][j]["weight"] for i in G[p].predecessors(j) )
                pk = [ G[p][i][j]["weight"]/sum_flow for i in G[p].predecessors(j) ]
                xk = [ lead_time[i,j] for i in G[p].predecessors(j)]

                LT_ = stats.rv_discrete(name='LEAD_TIME', values=(xk, pk))
                exp_d = LT_.mean() * mu_
                var_d = sigma_ * LT_.mean() + (mu_**2)*(LT_.std())**2

                #print(mu_, sigma_,  LT_.mean(), LT_.std(), exp_d, var_d)
                safety_ = exp_d + z*np.sqrt(var_d)
                #print(safety_)

                lt_col.append(LT_.mean())
                lt_std_col.append(LT_.std())
                dem_col.append(exp_d)
                dem_std_col.append(np.sqrt(var_d))
                safety_col.append(safety_)

            else: # a plant
                #print(j,p, plnt_prod_lt[j[5:],p])
                LT_ = plnt_prod_lt[j[5:],p]
                safety_ = mu_ * LT_ + z*np.sqrt(LT_*sigma_)
                #print(safety_)

                lt_col.append(LT_)
                lt_std_col.append(0.)
                dem_col.append(mu_)
                dem_std_col.append(sigma_)
                safety_col.append(safety_)
    safety_df = pd.DataFrame({"prod":prod_col, "node":node_col, "lead_time":lt_col, "lead_time_std":lt_std_col, "demand":dem_col, "demand_std":dem_std_col, "safety":safety_col})
    return safety_df

# %% ../nbs/06forecast.ipynb 155
def inventory_comparison(df: pd.DataFrame, predict: pd.DataFrame, service_level:float =0.95, LT: int=0) -> plotly.graph_objects.Figure:

    assert service_level < 1.0
    #通常の在庫方策（定常を仮定）
    #prepare demand arrays (real and predict)
    real_demand = df.demand.values
    predict_demand = np.array(predict.prediction_label)
    average_demand, standard_deviation = df.demand.mean(), df.demand.std()

    #正規分布を仮定して安全在庫係数を計算
    z = norm.ppf(service_level)
    safety_inventory = z*math.sqrt(LT)* standard_deviation
    target_inventory = safety_inventory + LT*average_demand
    
    I = np.zeros( len(predict_demand)+1 )
    I[0] = target_inventory
    NI = I[0] #net inventory 
    production = np.zeros(len(predict_demand)+1) 
    
    for t, date_ in enumerate(predict.index):
        if t>= len(predict.index)-LT:
            break
        if t< len(df):
            dem_ = real_demand[t]
        else:
            dem_ = predict_demand[t]
            
        NI = NI - dem_
        if NI < target_inventory:
            production[t] = target_inventory - NI
        NI = NI + production[t] #発注後在庫ポジション
        #在庫量の更新
        if t-LT>=0:
            I[t+1] = I[t] - dem_ + production[t-LT]
        else:
            I[t+1] = I[t] - dem_
    
    trace_inv1 = go.Scatter(
                x =  predict.index,
                y =  I,
                mode = 'lines',
                name ="定常在庫方策の在庫量"
            )
    
    #動的需要の在庫方策
    #compute redisuals
    try:
        df.set_index("date", inplace=True)
    except:
        pass

    #残差のデータから安全在庫量を計算
    residuals = (df.demand - predict.prediction_label).dropna()
    dem_ = residuals.values
    dem_.sort()
    safety_inventory = dem_[ int(len(dem_)*service_level) ]*math.sqrt(LT)
    #print(safety_inventory)

    #残差が正規分布と仮定した場合
    # average_demand, standard_deviation =  residuals.mean(), residuals.std()
    # safety_inventory = z*math.sqrt(LT)* standard_deviation
    # target_inventory = safety_inventory + LT*average_demand
        
    I = np.zeros( len(predict_demand) )
    I[0] = safety_inventory + sum(predict_demand[t] for t in range(LT))
    NI = I[0] #net inventory 
    production = np.zeros(len(predict_demand)) 
    basestock_level = np.zeros(len(predict_demand)) 
    for t, date_ in enumerate(predict.index):
        if t>= len(predict.index)-LT:
            break
        if t< len(df):
            dem_ = real_demand[t]
        else:
            dem_ = predict_demand[t]
        NI = NI - dem_
        target = safety_inventory + sum(predict_demand[t+k+1] for k in range(LT))
        basestock_level[t] = target
        production[t] = target - NI
        NI = NI + production[t] #発注後在庫ポジション
        #在庫量の更新
        if t < len(predict_demand):
            if t-LT>=0:
                I[t+1] = I[t] - dem_ + production[t-LT]
            else:
                I[t+1] = I[t] - dem_
        #print(I[t],demand_array[t],production[t])
    trace_inv2 = go.Scatter(
                x =  predict.index,
                y =  I,
                mode = 'lines',
                name ="動的在庫方策の在庫量"
            )
    data = [trace_inv1, trace_inv2]
        
    layout = go.Layout(
            title  ="在庫量の比較",
        )
    fig = go.Figure(data, layout)

    #prepare Table
    simulation_table = pd.DataFrame(predict.prediction_label)
    simulation_table.rename(columns={'prediction_label': 'prediction'}, inplace=True)
    
    dem_ = np.zeros(len(predict.prediction_label))
    for t,d in enumerate(real_demand):
        dem_[t] = d
    simulation_table["demand"] =  dem_ 
    simulation_table["inventory"] = I
    simulation_table["order"] = production
    simulation_table["basestock level"] = basestock_level

    return fig, simulation_table

# %% ../nbs/06forecast.ipynb 157
class Forecast(BaseModel):
    model_config = ConfigDict(arbitrary_types_allowed=True)
    cust_df: pd.DataFrame
    prod_df: pd.DataFrame
    demand_df: pd.DataFrame
    promo_df: Optional[pd.DataFrame] = None

    time_series_dfs: Dict[Tuple[str,str],pd.DataFrame] = None

    agg_period: str = "1d"
    forecast_periods: int = 1
    lagged_regressors: List[str] = []
    future_regressors: List[str] = []
    events: List[str] = []
    country: Optional[str] = None #Noneでない場合にはcountry_holidayを追加

    def prepare_dfs(self):
        if self.time_series_dfs is None:
            self.time_series_dfs = {}
        if "date" not in self.demand_df.columns:
            self.demand_df.reset_index(inplace=True)
    
        self.demand_df["date"] = pd.to_datetime(self.demand_df["date"])
        self.demand_df.set_index("date", inplace=True)
        pt = pd.pivot_table(self.demand_df, values= ["demand"]+self.future_regressors, index= ["date", "prod", "cust"])
 
        time_series_dfs = {}
        for c_row in self.cust_df.itertuples():
            for p_row in self.prod_df.itertuples():
                p = p_row.name
                c = c_row.name
                df = pt.xs(key=(p,c), level=(1,2)).resample(self.agg_period).sum()
                df.reset_index(inplace=True)
                self.time_series_dfs[p,c] = df
        return self.time_series_dfs
        
    def holt_winter(self, prod_name: str, cust_name: str, **kwargs):
        """
        Forecast using Holt Winter model in statsmodels
        """
        y = self.time_series_dfs[prod_name, cust_name].demand
        fit = ExponentialSmoothing(
                y,
                **kwargs
            ).fit()

        return fit.predict(0, len(y)+ self.forecast_periods), y

    # def bayes_dl(self, prod_name: str, cust_name: str, **kwargs):
    #     """
    #     Forecast with NeuralProphet
    #     """
    #     if self.promo_df is not None:
    #         promo_df = self.promo_df #本来なら事前に抽出？
    #         if "date" not in promo_df.columns:
    #             promo_df.reset_index(inplace=True)
    #         promo_df["date"] = pd.to_datetime(promo_df["date"])
    #         promo_df.set_index("date", inplace=True)
    #         promo_df = promo_df.resample(self.agg_period).sum()
    #         promo_df.reset_index(inplace=True)
    #         promo_df.rename(columns={"date": "ds"}, inplace=True)
    #         promo_df["ds"] = pd.to_datetime(promo_df["ds"]) 
    #     else:
    #         promo_df = None
        
    #     train_df = self.time_series_dfs[p, c]
    #     train_df.rename(columns={"date": "ds", "demand": "y"}, inplace=True) #Neural Prohet用
        
    #     model = NeuralProphet(**kwargs)
    #     for r in self.future_regressors:
    #         model.add_future_regressor(r, mode="multiplicative")   #mode (str) – additive (default) or multiplicative.
    #     for r in self.lagged_regressors:
    #         model.add_lagged_regressor(r) 
    #     for r in self.events:
    #         model.add_events(r)
    #     if self.country is not None:
    #         model.add_country_holidays(self.country) #文字のcheck？

    #     #予測用の未来のデータフレームを生成
    #     if self.promo_df is not None:
    #         promo_df = promo_df[ promo_df["ds"] > train_df["ds"].iloc[-1] ]
    #     future_df = model.make_future_dataframe(train_df, regressors_df= promo_df, 
    #                                          periods= self.forecast_periods, n_historic_predictions=True)
    #     return model, train_df, future_df

    def deep_learning(self, prod_name: str, cust_name: str):
        if self.time_series_dfs is None:
            self.prepare_dfs()
        df = time_series_dfs[p,c]
        train, future = make_forecast_df(df, promo_df= self.promo_df, agg_period= self.agg_period, forecast_periods = self.forecast_periods)
        learn = make_learn(train, horizon= None, classification=False)
        lr_min= learn.lr_find(show_plot=False) 
        #print(lr_min.valley)
        train_dl(learn, n_epoch = 30, lr_max = lr_min.valley*25, wd=2.) #, cbs=ShowGraphCallback()
        predict, error, r2 = predict_using_dl(learn, df, future, classification=False)
        #print(error, r2)
        return predict, error, r2

    def automl(self, prod_name: str, cust_name: str):
        if self.time_series_dfs is None:
            self.prepare_dfs()
        df = self.time_series_dfs[prod_name,cust_name]
        train, future = make_forecast_df(df, promo_df= self.promo_df, agg_period= self.agg_period, 
                                         forecast_periods = self.forecast_periods)
        best, result_df = automl_pycaret(train, horizon=None, num_bests=5, model_name=None)
        all_df = pd.concat([train,future]).drop(labels=["demand"],axis=1)
        if "date" not in df.columns:
            df.reset_index(inplace=True)
        first_date = df["date"].min()
        dates = pd.date_range(
                    start = first_date,
                    periods= len(df)+ self.forecast_periods, 
                    freq= self.agg_period)
        all_df.set_index(dates, inplace=True)
        predict_df = predict_model(best[0], all_df) #訓練＋未来で予測
        best_model_results = pull()
        metrics = best_model_results.iloc[0,:]
        error = metrics["RMSE"]
        r2 = metrics["R2"]
        best_name = metrics["Model"]

        #実需要量のプロット
        trace2 = go.Scatter(
            x =  df["date"],
            y =  df.demand,
            mode = 'markers',
            name ="実需要量 Demand"
        )
        #予測プロット
        trace1 = go.Scatter(
            x = predict_df.index,
            y = predict_df.prediction_label.values,
            mode = 'markers + lines',
            name = "予測 Forecast"
        )
        data = [trace1, trace2]
        
        layout = go.Layout(
            title  ="予測  Forecasting",
        )
        fig = go.Figure(data, layout)

        return predict_df, error, r2, best_model_results.index[0], best_name, fig, best, result_df 

    def inventory_comparison(self, df: pd.DataFrame, predict: pd.DataFrame, service_level:float = 0.95, LT: int=0):
        return inventory_comparison(df = df, predict = predict, service_level=service_level, LT = LT)

